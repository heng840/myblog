## Dataset Library
Core:   ```from datasets import load_dataset```

```python
from datasets import load_dataset

my_data = load_dataset()
my_data.map()
```
- æŸ¥çœ‹æ•°æ®åº“å±æ€§

A good practice when doing any sort of data analysis is to grab a small random sample to get a quick feel for the type of data youâ€™re working with. In ğŸ¤— Datasets, we can create a random sample by chaining the Dataset.shuffle() and Dataset.select() functions together:
```python
drug_sample = my_data["train"].shuffle(seed=42).select(range(1000))
# Peek at the first few examples
drug_sample[:3]
```
#### å¯ä»¥ä½¿ç”¨çš„æ–¹æ³•
1. rename_column
é‡å‘½åå±æ€§
2. filter
è¿‡æ»¤ä¸ºNoneçš„å€¼ï¼Œæˆ–è€…ä¸€äº›å…¶ä»–çš„è¦æ±‚
3. add_column
æ–°å¢ä¸€ä¸ªå±æ€§ã€‚ä¹Ÿå¯ä»¥ç”¨mapä»£æ›¿
4. map


### big data -hard to load ->memory-mapped file
è¿™æ˜¯Datasetè‡ªåŠ¨ä½¿ç”¨çš„æ–¹æ³•ï¼Œå¯ä»¥é™ä½RAMçš„ä½¿ç”¨ã€‚å¯¹äºä¸€èˆ¬çš„datasetï¼Œè¿™æ ·çš„é™ä½å†…å­˜çš„æ–¹æ³•å®Œå…¨è¶³å¤Ÿäº†

ä½†æ˜¯å¦‚æœdatasetè¿‡äºå·¨å¤§ï¼Œé‚£ä¹ˆå¯ä»¥ä½¿ç”¨streaming=Trueçš„æ–¹æ³•ï¼ŒåŠ¨æ€ä¸‹è½½æ•°æ®é›†ã€‚
```python
pubmed_dataset_streamed = load_dataset(
    "json", data_files=data_files, split="train", streaming=True
)
```
è¿™æ ·ï¼Œä¼šè¿”å›ä¸€ä¸ªIterableDataset ï¼Œè¾“å‡ºæ˜¯é€ä¸ªè¿”å›çš„ã€‚å› æ­¤éœ€è¦ç”¨ä¸Šï¼š
```python
next(iter(tokenized_dataset))
```





